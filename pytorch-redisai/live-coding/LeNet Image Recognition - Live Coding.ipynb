{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Object(object): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Object()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data to train on\n",
    "\n",
    "2. Model\n",
    "\n",
    "3. Training algorithm to train the model\n",
    "\n",
    "4. Validate model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.raw = sklearn.datasets.fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.raw.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X = t.raw.data.reshape(70000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.raw.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X = t.X.astype(np.float32)\n",
    "t.y = t.raw.target.astype(np.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(x, y, n=None):\n",
    "    if n is None:\n",
    "        n = np.random.randint(x.shape[0])\n",
    "    print(y[n])\n",
    "    _ = plt.imshow(x[n], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(t.X, t.y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train, t.X_test, t.y_train, t.y_test = \\\n",
    "    train_test_split(t.X, t.y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train.shape, t.X_test.shape, t.y_train.shape, t.y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to(t.device) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(t.X_train, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train_t = torch.from_numpy(np.expand_dims(t.X_train, axis=1)).to(t.device)\n",
    "t.X_test_t = torch.from_numpy(np.expand_dims(t.X_test, axis=1)).to(t.device)\n",
    "t.y_train_t = torch.from_numpy(t.y_train).to(t.device)\n",
    "t.y_test_t = torch.from_numpy(t.y_test).to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.y_train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient-Based Learning Applied to Document Recognition<br>\n",
    "Yann Lecun, Leon Bottou, Yoshua Bengio, Patrick Haffner<br>\n",
    "Proceedings of the IEEE 86(11):2278 - 2324 · December 1998 with 31,513 Reads<br>\n",
    "https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition\n",
    "\n",
    "\n",
    "```\n",
    "\"Layer C1 is a convolutional layer with six feature maps.\n",
    "Each unit in each feature map is connected to a 5 5 neighborhood \n",
    "in the input. The size of the feature maps is 28 28 which prevents \n",
    "connection from the input from falling off the boundary. C1 contains \n",
    "156 trainable parameters and 122 304 connections.\n",
    "\n",
    "Layer S2 is a subsampling layer with six feature maps of\n",
    "size 14 14. Each unit in each feature map is connected to a\n",
    "2 2 neighborhood in the corresponding feature map in C1.\n",
    "The four inputs to a unit in S2 are added, then multiplied by \n",
    "a trainable coefficient, and then added to a trainable bias.\n",
    "The result is passed through a sigmoidal function. \n",
    "The 2 2 receptive fields are nonoverlapping, therefore feature maps\n",
    "in S2 have half the number of rows and column as feature\n",
    "maps in C1. Layer S2 has 12 trainable parameters and 5880\n",
    "connections.\n",
    "\n",
    "Layer C3 is a convolutional layer with 16 feature maps.\n",
    "Each unit in each feature map is connected to several\n",
    "5 5 neighborhoods at identical locations in a subset of\n",
    "S2’s feature maps.\n",
    "\n",
    "[...]\n",
    "\n",
    "Layer S4 is a subsampling layer with 16 feature maps of\n",
    "size 5 5. Each unit in each feature map is connected to a\n",
    "2 2 neighborhood in the corresponding feature map in C3,\n",
    "in a similar way as C1 and S2. Layer S4 has 32 trainable\n",
    "parameters and 2000 connections.\n",
    "\n",
    "Layer C5 is a convolutional layer with 120 feature maps.\n",
    "Each unit is connected to a 5 5 neighborhood on all 16\n",
    "of S4’s feature maps. Here, because the size of S4 is also\n",
    "5 5, the size of C5’s feature maps is 1 1; this amounts\n",
    "to a full connection between S4 and C5. C5 is labeled as\n",
    "a convolutional layer, instead of a fully connected layer,\n",
    "because if LeNet-5 input were made bigger with everything\n",
    "else kept constant, the feature map dimension would be\n",
    "larger than 1 1.\n",
    "\n",
    "Layer F6 contains 84 units (the reason for this number\n",
    "comes from the design of the output layer, explained\n",
    "below) and is fully connected to C5. It has 10 164 trainable\n",
    "parameters.\n",
    "\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](lenet-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet_classic():\n",
    "    return nn.Sequential(\n",
    "        # C1, 28 x 28 x 1\n",
    "        nn.Conv2d(1, 6, kernel_size=5, stride=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        # S2\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        # S2: 14 x 14 x 6 \n",
    "        \n",
    "        # C3: \n",
    "        nn.Conv2d(6, 16, kernel_size=5, stride=1),\n",
    "        nn.ReLU(),\n",
    "        # C3: 10 x 10\n",
    "        \n",
    "        # S4:\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        # S4: 5 x 5 x 16\n",
    "        \n",
    "        # C5:\n",
    "        nn.Conv2d(16, 120, kernel_size=5, stride=1),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(84, 10),  # Last, how many values to output? \n",
    "        nn.LogSoftmax(dim=-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = Object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.model = create_lenet_classic().to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.output = loop.model(t.X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t.X.shape[1] < 32:\n",
    "    t.X = np.pad(t.X, (\n",
    "            (0, 0),\n",
    "            (2, 2),\n",
    "            (2, 2)),\n",
    "          mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(t.X, t.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train, t.X_test, t.y_train, t.y_test = \\\n",
    "    train_test_split(t.X, t.y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train_t = torch.from_numpy(np.expand_dims(t.X_train, axis=1)).to(t.device)\n",
    "t.X_test_t = torch.from_numpy(np.expand_dims(t.X_test, axis=1)).to(t.device)\n",
    "t.y_train_t = torch.from_numpy(t.y_train).to(t.device)\n",
    "t.y_test_t = torch.from_numpy(t.y_test).to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.model = create_lenet_classic().to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.opt = torch.optim.SGD(\n",
    "    loop.model.parameters(),\n",
    "    lr=1e-3,\n",
    "    momentum=0.9, \n",
    "    nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.outputs = loop.model(t.X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.loss_value = loop.loss(loop.outputs, t.y_train_t)\n",
    "loop.loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.loss_value.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.loss = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred_one_hot, y_true):\n",
    "    y_pred = y_pred_one_hot.max(dim=1)[1]\n",
    "    return (y_pred == y_true).sum().item() / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(net, data, epochs=3):\n",
    "    optim = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "    batch_size = 16\n",
    "    batches = int(data.X_train_t.shape[0] / batch_size)\n",
    "    print_every = batches / 10\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for b in range(batches):\n",
    "            start = b * batch_size\n",
    "            end = start + batch_size\n",
    "            x_batch = data.X_train_t[start : end]\n",
    "            y_batch = data.y_train_t[start : end]\n",
    "        \n",
    "             # Forward pass: compute predicted y by passing x to the model.\n",
    "            y_pred = net(x_batch)\n",
    "\n",
    "            # Compute and print loss.\n",
    "            loss = data.loss(y_pred, y_batch)\n",
    "\n",
    "            # Reset gradient\n",
    "            net.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model\n",
    "            # parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its\n",
    "            # parameters\n",
    "            optim.step()\n",
    "\n",
    "            if b % print_every == 1:\n",
    "                print(i, b, \n",
    "                      \"Loss:\", loss.item(), \n",
    "                      \"accuracy: \", accuracy(net(data.X_train_t), \n",
    "                                             data.y_train_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t.nn = create_lenet_classic().to(t.device)\n",
    "train_batch(t.nn, t, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.pred_y = t.nn(t.X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(t.pred_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_image(t.X_test, t.y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(t.nn(t.X_test_t), t.y_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test_n = np.random.randint(t.X_test.shape[0])\n",
    "t.test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.X_test[t.test_n].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t.X_test[t.test_n], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.y_test[t.test_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test_image = np.expand_dims(np.expand_dims(t.X_test[t.test_n], axis=0), axis=0)\n",
    "t.test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test_image_t = torch.from_numpy(t.test_image).to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = t.nn(t.test_image_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(logits[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(net, x_t, x, y, n=None):\n",
    "    if n is None:\n",
    "        n = np.random.randint(x.shape[0])\n",
    "    image_t = x_t[n]\n",
    "    pred_t = net(image_t.unsqueeze(0))\n",
    "    pred = torch.argmax(torch.exp(pred_t[0])).item()\n",
    "    print(n, ':', y[n], ' : ',  pred)\n",
    "    plt.imshow(x[n], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(t.nn, t.X_test_t, t.X_test, t.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wrong_image(net, x, y):\n",
    "    while True:\n",
    "        n = np.random.randint(x.shape[0])\n",
    "        image = np.expand_dims(np.expand_dims(x[n], axis=0), axis=0).astype(np.float32)\n",
    "        image_t = torch.from_numpy(image)\n",
    "        pred_t = net(image_t)\n",
    "        pred = torch.argmax(torch.exp(pred_t[0])).item()\n",
    "        if pred != y[n]:\n",
    "            print(n, ':', y[n], ' : ',  pred)\n",
    "            plt.imshow(x[n], cmap=\"gray\")\n",
    "            break\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.wrong_n = find_wrong_image(t.nn.cpu(), t.X_test, t.y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wire the LeNet-5 to RedisAI and Twitter. Write a digit on your phone, send to your twitter, recognize, post back the prediction.\n",
    "<br>\n",
    "<br>\n",
    "1. Traffic Signs. \n",
    "  1. Re-train the network using traffic signs, http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset. Note: convert images to grayscale for this assignment.\n",
    "  1. Upload to RedisAI. \n",
    "  1. Take a picture of the real trafic sign (when safe to do so), post it to your twitter, check the prediction.\n",
    "<br>\n",
    "<br>\n",
    "1. Adapt LeNet-5 to work with RGB color images, and train on full-color images of traffic signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
